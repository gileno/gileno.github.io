<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Usando o Scrapy e o Rethinkdb para capturar e armazenar dados imobiliários - Parte II</title>
  <meta name="description" content="Introdução">
  
  <meta name="author" content="Gileno Filho">
  <meta name="copyright" content="&copy; Gileno Filho 2015">
  

  <!-- External libraries -->
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/styles/monokai_sublime.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.7.1/css/lightbox.css">

  <!-- Favicon and other icons (made with http://www.favicon-generator.org/) -->
  <link rel="shortcut icon" href="/assets/icons/favicon.ico" type="image/x-icon">
	<link rel="icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="apple-touch-icon" sizes="57x57" href="/assets/icons/apple-icon-57x57.png">
	<link rel="apple-touch-icon" sizes="60x60" href="/assets/icons/apple-icon-60x60.png">
	<link rel="apple-touch-icon" sizes="72x72" href="/assets/icons/apple-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="76x76" href="/assets/icons/apple-icon-76x76.png">
	<link rel="apple-touch-icon" sizes="114x114" href="/assets/icons/apple-icon-114x114.png">
	<link rel="apple-touch-icon" sizes="120x120" href="/assets/icons/apple-icon-120x120.png">
	<link rel="apple-touch-icon" sizes="144x144" href="/assets/icons/apple-icon-144x144.png">
	<link rel="apple-touch-icon" sizes="152x152" href="/assets/icons/apple-icon-152x152.png">
	<link rel="apple-touch-icon" sizes="180x180" href="/assets/icons/apple-icon-180x180.png">
	<link rel="icon" type="image/png" sizes="192x192"  href="/assets/icons/android-icon-192x192.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/assets/icons/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="96x96" href="/assets/icons/favicon-96x96.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/assets/icons/favicon-16x16.png">
	<link rel="manifest" href="/assets/icons/manifest.json">
	<meta name="msapplication-TileColor" content="#ffffff">
	<meta name="msapplication-TileImage" content="/assets/icons/ms-icon-144x144.png">
	<meta name="theme-color" content="#ffffff">

	<!-- Facebook OGP cards -->
  <meta property="og:description" content="Introdução" />
  <meta property="og:url" content="http://www.gilenofilho.com.br" />
  <meta property="og:site_name" content="Gileno Filho" />
  <meta property="og:title" content="Usando o Scrapy e o Rethinkdb para capturar e armazenar dados imobiliários - Parte II" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="http://www.gilenofilho.com.br/assets/eu2-thumb.png" />
  <meta property="og:image:type" content="image/png" />
  <meta property="og:image:width" content="612" />
  <meta property="og:image:height" content="605" />

  <!-- Twitter: card tags -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Usando o Scrapy e o Rethinkdb para capturar e armazenar dados imobiliários - Parte II">
  <meta name="twitter:description" content="Introdução">
  <meta name="twitter:image" content="http://www.gilenofilho.com.br/assets/eu2-thumb.png">
  <meta name="twitter:url" content="http://www.gilenofilho.com.br">

  

	<!-- Site styles -->
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://www.gilenofilho.com.br//usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-ii">
  <link rel="alternate" type="application/rss+xml" title="Gileno Filho" href="http://www.gilenofilho.com.br//feed.xml" />
</head>


  <body>

    <header class="navigation" role="banner">
  <div class="navigation-wrapper">
    <a href="/" class="logo">
    	
      <span>Gileno Filho</span>
      
    </a>
    <a href="javascript:void(0)" class="navigation-menu-button" id="js-mobile-menu">
    	<i class="fa fa-bars"></i>
    </a>
    <nav role="navigation">
      <ul id="js-navigation-menu" class="navigation-menu show">
      	
          
          <li class="nav-link"><a href="/artigos/">Artigos</a>
          
        
          
        
          
        
          
        
          
          <li class="nav-link"><a href="/sobre/">Sobre</a>
          
        
          
        
          
        
          
        
          
        
      </ul>
    </nav>
  </div>
</header>


    <div class="page-content">
        <div class="post">

<div class="post-header-container " >
	<div class="scrim ">
		<header class="post-header">
		  <h1 class="title">Usando o Scrapy e o Rethinkdb para capturar e armazenar dados imobiliários - Parte II</h1>
		  <p class="info">by <strong>Gileno Filho</strong></p>
		</header>
	</div>
</div>

<div class="wrapper">

 <span class="page-divider">
  <span class="one"></span>
  <span class="two"></span>
</span>
 

<section class="post-meta">
	<div class="post-date">June 29, 2015</div>
	<div class="post-categories">
	in 
	  
		<a href="/category/tutoriais">Tutoriais</a>
	  
	
	</div>
</section>

<article class="post-content">
  <h3 id="introduo">Introdução</h3>

<p>Olá pessoal, esta é a parte II da série sobre o Scrapy, abaixo os links para todos os artigos da série:</p>

<ul>
  <li><a href="http://gilenofilho.com.br/usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-i/">Parte I - Configurando e rodando o Scrapy</a></li>
  <li><a href="http://gilenofilho.com.br/usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-ii/">Parte II - Instalando, configurando e armazenando os dados no Rethinkdb</a></li>
  <li><a href="http://gilenofilho.com.br/usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-iii/">Parte III - Deploy do projeto Scrapy</a></li>
</ul>

<p>Na parte I mostrei como instalar/configurar e rodar seu projeto scrapy no site do OLX. Nesse artigo vamos ver como salvar as informações resgatadas do crawler.</p>

<p>Antes de ir ao código é importante frisar que o Scrapy sempre que recebe um <code>scrapy.Request</code> dentro de uma <strong>callback</strong> irá realizar outra requisição, entretanto se ao invés disso, você retornar um dicionário ou um objeto que herde de <code>scrapy.Item</code>, o Scrapy irá entender que aquele <strong>callback</strong> acaba de resgatar uma informação que deve ser processada e vai enviar esse item ou dicionário para a fila de processamento - os <strong>pipelines</strong>.</p>

<h3 id="vamos-l">Vamos lá</h3>

<p>Dentro do <strong>callback</strong> que definimos no último <a href="https://gist.github.com/gileno/39d3d663a314a56c8e2b#file-olx-py">código da parte I</a>, nós vimos como pegar uma informação da requisição via <strong>xpath</strong> e exibir essa informação no nosso log, agora vamos fazer a lógica de informar ao Scrapy que dados estamos coletando e por fim vamos criar um <strong>pipeline</strong> para processar esses dados.</p>

<p>O código ficará assim:</p>

<script src="https://gist.github.com/gileno/6fbc0cbf1fed942b85de.js"></script>

<p>A grande mudança é que agora nós estamos coletando bem mais informações sobre o imóvel, ainda da forma <strong>crua</strong> mas limpeza desses dados ficaria para um possível tratamento estatístico… Estamos criando um dicionário chamado <code>item</code> e no final usamos o <code>yield</code> para retorná-lo. A primeira informação que está sendo guardada são as fotos, quer dizer, os links para as fotos, utilizando o <code>extract()</code> ou invés do <code>extract_first()</code> pois provavelmente irá retornar mais de um elemento no <strong>xpath</strong> da fotos.</p>

<p>Todas as outras informações são simples de coletar, basta um pequeno <strong>xpath</strong> utilizando a função <strong>normalize-space</strong> para remover caracteres indesejados como <strong>\t</strong>* a única informação que necessita de algo diferente é a data, ela não está num formato interessante mas conseguimos pegar ao menos o dia, mês e hora utilizando a expressão regular presente na linha <a href="https://gist.github.com/gileno/6fbc0cbf1fed942b85de#file-olx-py-L55">55</a>. Como não tenho certeza se todos os imóveis irão cair nessa regex, faço uma pequena verificação se a regex obteve êxito.</p>

<p>Agora que estamos retornando nossas informações basta rodar novamente o crawler:</p>

<div class="highlight"><pre><code class="language-sh" data-lang="sh">scrapy crawl olx</code></pre></div>

<p>Devemos ver algo assim:</p>

<div class="highlight"><pre><code class="language-sh" data-lang="sh">...
2015-06-28 21:49:38 <span class="o">[</span>scrapy<span class="o">]</span> DEBUG: Scraped from &lt;<span class="m">200</span> http://pe.olx.com.br/grande-recife/imoveis/apto-kitnet-c-2-qtos-j-piedade-p-casal-s-filhos-ou-solteiros-95174559&gt;
<span class="o">{</span><span class="s1">&#39;date&#39;</span>: u<span class="s1">&#39;28 Junho 19:10&#39;</span>, <span class="s1">&#39;title&#39;</span>: u<span class="s1">&#39;Apto Kitnet c/2 qtos, J.Piedade p/casal s/filhos ou solteiros&#39;</span>, <span class="s1">&#39;url&#39;</span>: <span class="s1">&#39;http://pe.olx.com.br/grande-recife/imoveis/apto-kitnet-c-2-qtos-j-piedade-p-casal-s-filhos-ou-solteiros-95174559&#39;</span>, <span class="s1">&#39;price&#39;</span>: u<span class="s1">&#39;R$500&#39;</span>, <span class="s1">&#39;photos&#39;</span>: <span class="o">[</span>u<span class="s1">&#39;http://img.olx.com.br/images/14/145528016191488.jpg&#39;</span>, u<span class="s1">&#39;http://img.olx.com.br/images/14/147528011762579.jpg&#39;</span>, u<span class="s1">&#39;http://img.olx.com.br/images/14/141528016763146.jpg&#39;</span>, u<span class="s1">&#39;http://img.olx.com.br/images/14/149528019791781.jpg&#39;</span><span class="o">]</span>, <span class="s1">&#39;details&#39;</span>: u<span class="s1">&#39;Local adequado para quem gosta de tranquilidade e sil\xeancio, apto com 2 qtos, bem conservado, todo na cer\xe2mica, ideal para casal ou para solteiros SEM FILHOS E SEM ANIMAIS DE ESTIMA\xc7\xc3O. N\xc3O TEM GARAGEM PARA CARROS E NEM LUGAR PARA COLOCAR NA FRENTE, dispomos apenas de vagas para motos, contadores de luz individuais, banheiro com box, ambiente familiar, n\xe3o adequado para quem gosta de briga, som alto e bebedeira. Local tranquilo, rua sem asfalto, condom\xednio fechado e muito organizado perto de com\xe9rcio, transporte, etc. Fica em Jardim Piedade Pr\xf3ximo ao supermercado todo dia, na Rua do Sossego N\xba 100 CEP 54420680. Valor do aluguel R$ 500,00 com \xe1gua inclusa. N\xe3o exigimos fiador, contrato m\xednimo de 6 meses. Falar com \xc2ngela pelo n\xfamero 81-97961646 tim e 88226083 oi. Mais fotos do interior do apto via Whatzapp.&#39;</span>, <span class="s1">&#39;address&#39;</span>: u<span class="s1">&#39;Localiza\xe7\xe3o Munic\xedpio: Jaboat\xe3o dos Guararapes Bairro: Piedade CEP do im\xf3vel: 54410-695&#39;</span>, <span class="s1">&#39;source_id&#39;</span>: u<span class="s1">&#39;95174559&#39;</span><span class="o">}</span>
2015-06-28 21:49:39 <span class="o">[</span>scrapy<span class="o">]</span> DEBUG: Crawled <span class="o">(</span>544<span class="o">)</span> &lt;GET http://pe.olx.com.br/grande-recife/imoveis/apto-no-10-andar-em-quase-beira-mar-03qtos-95175476&gt; <span class="o">(</span>referer: http://pe.olx.com.br/imoveis/aluguel<span class="o">)</span>
...</code></pre></div>

<p>Por padrão o Scrapy irá apenas logar a informação coletada, vamos agora implementar um pipeline para armazenar a informação no banco da dados <a href="http://www.rethinkdb.com/">rethinkdb</a>. Eu resolvi utilizar o rethinkdb porque gosto de experimentar novos bancos de dados e ele tem diversos aspectos interessantes do NoSQL e algumas facilidades dos bancos relacionais clássicos, em outro artigo eu entro em mais detalhes sobre esse banco de dados - qualquer coisa basta citar essa escolha nos comentários - por hora basta saber que ele armazena documentos no formato JSON.</p>

<p>Primeiro precisamos baixar e instalar, algo que é bem simples, basta acessar o site oficial e escolher o pacote para o seu sistema operacional:</p>

<p>http://www.rethinkdb.com/docs/install/</p>

<p>Após a instalação é preciso colocar o rethinkdb para rodar, basta digitar o comando:</p>

<div class="highlight"><pre><code class="language-sh" data-lang="sh">rethinkdb</code></pre></div>

<p>Com o banco de dados rodando você tem acesso a uma interface administrativa acessando:</p>

<p>http://localhost:8080/</p>

<p>Eu prefiro colocar o banco de dados parar rodar só quando vou utilizar, faço isso tanto com os relacionais quanto os não-relacionais mas se desejar pode iniciar o rethinkdb assim que iniciar o sistema:</p>

<p>http://rethinkdb.com/docs/start-on-startup/</p>

<p>Com o banco de dados rodando, devemos acessar a interface administrativa e criar um banco de dados chamado <strong>scrapy_olx</strong>. Depois de criado o banco, vamos instalar o driver do rethinkdb:</p>

<div class="highlight"><pre><code class="language-sh" data-lang="sh">pip install rethinkdb</code></pre></div>

<p>Agora vamos adicionar às configurações do nosso projeto Scrapy, arquivo <strong>settings.py</strong>, as informações de acesso ao rethinkdb e a configuração <code>ITEM_PIPELINES</code> indicando o pipeline que iremos criar.</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">RETHINKDB</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">&#39;table_name&#39;</span><span class="p">:</span> <span class="s">&#39;items&#39;</span><span class="p">,</span> <span class="s">&#39;db&#39;</span><span class="p">:</span> <span class="s">&#39;scrapy_olx&#39;</span>
<span class="p">}</span>
<span class="n">ITEM_PIPELINES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">&#39;scrapy_olx.pipelines.RethinkdbPipeline&#39;</span><span class="p">:</span> <span class="mi">1</span>
<span class="p">}</span></code></pre></div>

<p>Com as configurações inseridas no <strong>settings.py</strong> vamos alterar o arquivo pipelines.py para adicionar a classe <code>RethinkdbPipeline</code>, que irá processar nossos dados e inserir no rethinkdb:</p>

<script src="https://gist.github.com/gileno/3219ab7caf5be6da5478.js"></script>

<p>A primeira coisa que fazemos é importar o módulo do rethinkdb, eles recomendam usar o namespace <strong>r</strong> mas é opcional.</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">rethinkdb</span> <span class="kn">as</span> <span class="nn">r</span></code></pre></div>

<p>Cada classe que irá ser um <a href="http://doc.scrapy.org/en/1.0/topics/item-pipeline.html#item-pipeline">pipeline</a> pode implementar 4 métodos:</p>

<ul>
  <li><a href="http://doc.scrapy.org/en/1.0/topics/item-pipeline.html#process_item">process_item</a></li>
  <li><a href="http://doc.scrapy.org/en/1.0/topics/item-pipeline.html#open_spider">open_spider</a></li>
  <li><a href="http://doc.scrapy.org/en/1.0/topics/item-pipeline.html#close_spider">close_spider</a></li>
  <li><a href="http://doc.scrapy.org/en/1.0/topics/item-pipeline.html#from_crawler">from_crawler</a></li>
</ul>

<p>No método <code>from_crawler</code> nós temos acesso a todos os principais componentes do Scrapy, incluindo as configurações e por isso implementamos este método para pegar as informações de acesso ao rethinkdb.</p>

<p>Nos método <code>open_spider</code> e <code>close_spider</code> fazemos a abertura e fechamento da conexão com o rethinkdb, para evitar erros há uma pequena verificação se a tabela já existe no banco de dados, caso não exista ela é criada.</p>

<p>Finalmente no método <code>process_item</code> inserimos o item no banco de dados, o rethinkdb aceita dicionários que tem uma estrutura semelhante aos JSON’s que é a forma de armazenamento dele.</p>

<p>Agora vamos rodar novamente o crawler:</p>

<div class="highlight"><pre><code class="language-sh" data-lang="sh">scrapy crawl olx</code></pre></div>

<p>O crawler deve rodar durante algumas horas mas ao acessar a interface administrativa do rethinkdb irá perceber que o número de documentos indicados na tabela <strong>items</strong> vai aumentando.</p>

<h3 id="resumo">Resumo</h3>

<p>Neste artigos vimos como retornar ao Scrapy as informações coletadas, depois tivemos uma visão geral do rethinkdb um banco conhecido como <strong>scalable JSON database</strong>, ele é open-source e construído para aplicações web em tempo real.</p>

<p>Por fim fizemos um pipeline para ver como podemos processar um item coletado pelo crawler, utilizamos todos os 4 métodos que podem ser implementados pelo pipeline e são chamados pelo Scrapy.</p>

<p>No próximo artigo iremos ver como fazer deploy do projeto Scrapy, pois normalmente não é interessante deixar o crawler rodando na sua máquina, o mais comum é colocar em algum servidor na nuvem.</p>

</article>



<section class="tags">
	<strong>Tags:</strong> <a href="/tag/python">python</a>,&nbsp;<a href="/tag/dados">dados</a>
</section>



<section class="rss">
	<p class="rss-subscribe text"><strong>Subscribe <a href="/feed.xml">via RSS</a></strong></p>
</section>

<section class="share">
  <span>Share: </span>
  
  	
  		<a href="//twitter.com/share?text=Usando+o+Scrapy+e+o+Rethinkdb+para+capturar+e+armazenar+dados+imobili%C3%A1rios+-+Parte+II&url=http://www.gilenofilho.com.br//usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-ii.html&via=GilenoFilho"
  			onclick="window.open(this.href, 'twitter-share', 'width=550,height=255');return false;">
  			<i class="fa fa-twitter-square fa-lg"></i>
  		</a>
  	
  	
  	
  	
  	
  
  	
  	
  	
  	
  	
  
  	
  	
  	
  	
  		<a href="//www.linkedin.com/shareArticle?mini=true&url=http://www.gilenofilho.com.br//usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-ii.html"
  			onclick="window.open(this.href, 'linkedin-share', 'width=550,height=255');return false;">
  			<i class="fa fa-linkedin-square fa-lg"></i>
  		</a>
  	
  	
  
  	
  	
  	
  	
  	
  
</section>



<section class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_shortname = 'gilenofilho';
	var disqus_identifier = 'gilenofilho.com.br' + window.location.pathname;
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>



</div>
</div>

    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h3 class="footer-heading">Gileno Filho</h3>

    <div class="site-navigation">

    	<p><strong>Links</strong></p>
      <ul class="pages">
        
        
          <li class="nav-link"><a href="/artigos/">Artigos</a>
        
        
        
        
        
        
        
        
        
          <li class="nav-link"><a href="/sobre/">Sobre</a>
        
        
        
        
        
        
        
        
        
        
            <li class="nav-link">
                <a href="/feed.xml">RSS</a>
            </li>
      </ul>
    </div>

    <div class="site-contact">

    	<p><strong>Contato</strong></p>
      <ul class="social-media-list">
      	<li>
      		<a href="mailto:contato@gilenofilho.com.br">
	      		<i class="fa fa-envelope-o"></i>
	      		<span class="username">contato@gilenofilho.com.br</span>
      		</a>
      	</li>

      	
	      	
	      	<li>
	          <a href="https://twitter.com/gilenofilho" title="Follow me on Twitter">
	            <i class="fa fa-twitter"></i>
	            <span class="username">GilenoFilho</span>
	          </a>
	        </li>
	      	
      	
	      	
	      	<li>
	          <a href="https://github.com/gileno" title="Fork me on GitHub">
	            <i class="fa fa-github"></i>
	            <span class="username">gileno</span>
	          </a>
	        </li>
	      	
      	
	      	
	      	<li>
	          <a href="https://br.linkedin.com/in/gilenofilho" title="Connect with me on LinkedIn">
	            <i class="fa fa-linkedin"></i>
	            <span class="username">Gileno Filho</span>
	          </a>
	        </li>
	      	
      	
	      	
	      	<li>
	          <a href="https://www.youtube.com/channel/UCThem2-TpI1kJoNqf_hFZOQ" title="Subscribe on YouTube">
	            <i class="fa fa-youtube"></i>
	            <span class="username">Gileno Filho</span>
	          </a>
	        </li>
	      	
      	

      </ul>
    </div>

    <div class="site-signature">
    	<p class="rss-subscribe text">
            <strong>Inscreva-se</strong>
            <form action="//gilenofilho.us11.list-manage.com/subscribe/post?u=42028a9587ab7791c65804500&amp;id=cf58dbb2d8" method="post">
                <input type="text" name="EMAIL" value="" placeholder="Email" />
            </form>
        </p>
      <p class="text">Cursos, tutoriais e palestras sobre o mundo de tecnlogia e ciência</p>
    </div>

  </div>

</footer>

<!-- Scripts -->
<script src="//code.jquery.com/jquery-1.11.2.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/highlight.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.7.1/js/lightbox.min.js"></script>
<script>

$(document).ready(function() {

	// Syntax highlighting
	hljs.initHighlightingOnLoad();

	// Header
  var menuToggle = $('#js-mobile-menu').unbind();
  $('#js-navigation-menu').removeClass("show");
  menuToggle.on('click', function(e) {
    e.preventDefault();
    $('#js-navigation-menu').slideToggle(function(){
      if($('#js-navigation-menu').is(':hidden')) {
        $('#js-navigation-menu').removeAttr('style');
      }
    });
  });


});

</script>


<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-15015773-2', 'auto');
  ga('send', 'pageview', {
  	'page': '/usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-ii',
  	'title': 'Usando o Scrapy e o Rethinkdb para capturar e armazenar dados imobiliários - Parte II'
  });
</script>



  </body>

</html>
