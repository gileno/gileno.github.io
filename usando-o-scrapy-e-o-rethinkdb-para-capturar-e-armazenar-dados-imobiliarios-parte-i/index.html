<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml"
    itemscope itemtype="http://schema.org/Blog"
    lang="pt">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0"/>
        <meta http-equiv="content-language" content="pt-br">
        <meta name="robots" content="index, follow">
        <meta name="description" content="Website Gileno Filho"/>
        <meta name="keywords" content="programação, python, recife, desenvolvimento, data science"/>
        <meta name="author" content="Gileno Filho">
        <meta name="generator" content="Pelican">
        <title>Usando o Scrapy e o Rethinkdb para capturar e armazenar dados imobiliários - Parte I | Gileno Filho</title>

        <!-- Feeds -->
            <link href="http://www.gilenofilho.com.br/feeds.atom" type="application/atom+xml" rel="alternate" title="Gileno Filho ATOM Feed"/>
            <link href="http://www.gilenofilho.com.br/feeds.rss" type="application/rss+xml" rel="alternate" title="Gileno Filho RSS Feed"/>

        <!-- CSS  -->
        <link rel="stylesheet" href="/theme/css/font-awesome.min.css">
        <link href="/theme/css/bootstrap.css" type="text/css" rel="stylesheet" />
        <link href="/theme/css/style.css" type="text/css" rel="stylesheet" />
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
          <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
        <![endif]-->

<link href="/theme/css/pygments.css" type="text/css" rel="stylesheet" media="screen,projection"/>
        <!-- Metadata -->
    <!-- OpenGraph -->
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Usando o Scrapy e o Rethinkdb para capturar e armazenar dados imobiliários - Parte I"/>
    <meta property="og:url" content="http://www.gilenofilho.com.br/usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-i"/>
    <meta property="og:site_name" content="Gileno Filho"/>
    <meta property="og:description" content="Introdução Olá pessoal, a algum tempo que estou organizando minha agenda para voltar a trabalhar em alguns Web Crawlers para capturar dados..."/>
    <meta property="og:image" content="http://www.gilenofilho.com.brimages/eu.jpg"/>

    <!-- Twitter -->
    <meta name="twitter:card" content="summary"/>
    <meta name="twitter:site" content="@gilenofilho"/>
    <meta name="twitter:creator" content="@gilenofilho"/>
    <meta name="twitter:domain" content="www.gilenofilho.com.br"/>
    <meta name="twitter:title" content="Usando o Scrapy e o Rethinkdb para capturar e armazenar dados imobiliários - Parte I"/>
    <meta name="twitter:description" content="Introdução Olá pessoal, a algum tempo que estou organizando minha agenda para voltar a trabalhar em alguns Web Crawlers para capturar dados..."/>
    <meta name="twitter:image:src" content="http://www.gilenofilho.com.brimages/eu.jpg"/>

    <!-- Article meta -->
    <meta property="article:author" content="Gileno Filho"/>
    <meta property="article:section" content="tutoriais"/>
    <meta property="article:tag" content="python, dados"/>
    <meta property="article:published_time" content="2015-06-25T14:23:00-03:00"/>

    <!-- Google+ -->
    <meta itemprop="name" content="Usando o Scrapy e o Rethinkdb para capturar e armazenar dados imobiliários - Parte I"/>
    <meta itemprop="description" content="Introdução Olá pessoal, a algum tempo que estou organizando minha agenda para voltar a trabalhar em alguns Web Crawlers para capturar dados..."/>
    <meta itemprop="image" content="http://www.gilenofilho.com.brimages/eu.jpg"/>

    <!-- General purpose meta -->
    <meta name="description" content="Introdução Olá pessoal, a algum tempo que estou organizando minha agenda para voltar a trabalhar em alguns Web Crawlers para capturar dados..."/>
    <meta name="keywords" content="python, dados"/>

        <!-- Google Analytics -->
        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
          ga('create', 'UA-15015773-2', 'auto');
          ga('send', 'pageview');
        </script>

    </head>

    <body>
        <header>
<!-- Fixed navbar -->
<div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/">Gileno Filho</a>
    </div>
    <div class="navbar-collapse collapse navbar-right">
      <ul class="nav navbar-nav">
        <li><a href="/">Início</a></li>
          <li ><a href="/sobre">Sobre</a></li>
          <li ><a href="/categorias/cursos/">Cursos</a></li>
          <li ><a href="/categorias/palestras/">Palestas</a></li>
          <li ><a href="/categorias/tutoriais/">Tutoriais</a></li>
          <li ><a href="/categorias/utils/">Utils</a></li>
      </ul>
    </div><!--/.nav-collapse -->
  </div>
</div>            <div id="blue">
                <div class="container">
                    <div class="row">
                        <h3>
    programador, cientista, pythonista e minimalista. Recife, Brasil
</h3>
                    </div><!-- /row -->
                </div> <!-- /container -->
            </div><!-- /blue -->
        </header>
        <main>
            <!-- Content -->
            <div class="container mtb">
                <div class="col-md-8">

<ol class="breadcrumb">
    <li>
    <a title="Gileno Filho Home" href="/"><i class="fa fa-home pr-10"></i> Início</a>
    </li>
        <li>
        <a title="tutoriais|escape" href="/categorias/tutoriais">tutoriais</a>
        </li>
        <li>Usando o Scrapy e o Rethinkdb para capturar e armazenar dados imobiliários - Parte I</li>
</ol><article>
    <a href="/usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-i"><h3 class="ctitle">Usando o Scrapy e o Rethinkdb para capturar e armazenar dados imobiliários - Parte I</h3></a>
    <p>
        Publicado em:  <time datetime="2015-06-25T14:23:00-03:00">Qui 25 junho 2015</time>.
        |
        Por: <a href="/autores/gileno-filho">Gileno Filho</a>
        |
        Arquivado em: <a href="/categorias/tutoriais">tutoriais</a>
    </p>
    <h3>Introdução</h3>
<p>Olá pessoal, a algum tempo que estou organizando minha agenda para voltar a trabalhar em alguns <a href="https://pt.wikipedia.org/wiki/Web_crawler">Web Crawlers</a> para capturar dados imobiliários que é um tipo de dado que gosto de trabalhar. Assim resolvi publicar esse artigo, que fará parte de uma série de 3, onde irei mostrar como fazer um crawler usando o <a href="http://scrapy.org/">Scrapy</a> e como armazenar num banco de dados que muito me interessa, o <a href="http://www.rethinkdb.com/">rethinkdb</a>.</p>
<h3>Agenda</h3>
<ul>
<li><a href="http://gilenofilho.com.br/usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-i/">Parte I - Configurando e rodando o Scrapy</a></li>
<li><a href="http://gilenofilho.com.br/usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-ii/">Parte II - Instalando, configurando e armazenando os dados no Rethinkdb</a></li>
<li><a href="http://gilenofilho.com.br/usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-iii/">Parte III - Deploy do projeto Scrapy</a></li>
</ul>
<h3>Vamos lá</h3>
<p>O Scrapy é um framework para facilitar o desenvolvimento de crawlers, pois mesmo sendo fácil fazer um crawler usando o built-in do Python como o <a href="https://docs.python.org/2/library/urllib.html">urllib</a>, ou bibliotecas externas como <a href="http://docs.python-requests.org/en/latest/">requests</a>, fica mais rápido e prático utilizar um conjunto de ferramentas desenhados para este fim, é o famoso "batteries included".</p>
<p>Para instalar o Scrapy vamos utilizar o pip (supondo que já esteja num <a href="https://virtualenv.pypa.io/en/latest/">virtualenv</a>):</p>
<div class="highlight"><pre><span></span>pip install scrapy
</pre></div>


<p>Após instalar o scrapy você terá disponível o comando "scrapy" mais detalhes sobre as opções dele aqui:</p>
<p>http://doc.scrapy.org/en/1.0/topics/commands.html</p>
<p>O scrapy é composto de "spiders" que é a parte do código que irá definir que páginas serão acessadas para capturar informações, "items" que são as informações que serão extraídas das páginas e os "pipelines" que irão definir como esses "items" serão processados.</p>
<p>Um exemplo simples de um crawler utilizando o Scrapy:</p>
<script src="https://gist.github.com/gileno/8579ef62f5a700ca99d4.js"></script>

<p>Para rodar basta utilizar o comando scrapy:</p>
<div class="highlight"><pre><span></span>scrapy runspider gilenofilho.py
</pre></div>


<p>Você verá algo assim:</p>
<div class="highlight"><pre><span></span>...
2015-06-22 18:26:07 [scrapy] DEBUG: Redirecting (301) to &lt;GET http://gilenofilho.com.br/&gt; from &lt;GET http://www.gilenofilho.com.br/&gt;
2015-06-22 18:26:07 [scrapy] DEBUG: Crawled (200) &lt;GET http://gilenofilho.com.br/&gt; (referer: None)
2015-06-22 18:26:07 [gilenofilho] DEBUG: Hello World: http://gilenofilho.com.br/
2015-06-22 18:26:07 [scrapy] INFO: Closing spider (finished)
2015-06-22 18:26:07 [scrapy] INFO: Dumping Scrapy stats:
...
</pre></div>


<p>Uma Spider é basicamente uma classe que herda de <code>scrapy.Spider</code> o atributo <code>start_urls</code> está definindo as urls que devem ser acessadas inicialmente, você pode definir um método <code>starts_requests</code> que deve retornar uma lista de <code>scrapy.Request</code> através da keyword <code>yield</code>, assim:</p>
<p>Obs: a implementação padrão do <code>starts_requests</code> procura o atributo <code>start_urls</code> e chama o método <code>parse</code>.</p>
<script src="https://gist.github.com/gileno/83720a8c73a52685e399.js"></script>

<p>Deve se utilizar <code>yield</code> e passar um <strong>callback</strong> para a <code>scrapy.Request</code> pois o scrapy faz requisições assíncronas, isto é, não espera a requisição inicial acabar para fazer uma nova requisição, e desta forma utiliza o conceito de geradores em Python, você pode ver mais detalhes de como geradores funcionam acessando as palestras de Luciano Ramalho em: http://pt.slideshare.net/ramalho/.</p>
<p>O scrapy tem o conceito de projeto onde ficam organizados as "Spiders", "items" e "pipelines". Para criar um projeto scrapy basta utilizar o comando:</p>
<div class="highlight"><pre><span></span>scrapy startproject nome_do_projeto
</pre></div>


<p>Você verá que uma estrutura de diretórios e arquivos será criada para que facilite o crescimento do seu crawler. Eu criei um projeto chamado <strong>scrapy_olx</strong> e meu sistema de diretórios ficou assim:</p>
<div class="highlight"><pre><span></span>scrapy_olx
- scrapy_olx
- - spiders
- - - __init__.py
- - __init__.py
- - items.py
- - pipelines.py
- - settings.py
- scrapy.cfg
</pre></div>


<p>Agora vamos criar nosso primeiro Spider, com o comando:</p>
<div class="highlight"><pre><span></span>scrapy genspider olx pe.olx.com.br
</pre></div>


<p>Estou criando um crawler para capturar os imóveis de Pernambuco (PE) e esta é a url inicial no OLX. Dentro do diretório <strong>spiders</strong> foi criado um arquivo chamado olx.py contendo o esqueleto do nosso código, vou modificar o <strong>starts_urls</strong> para começar com a url dos imóveis para alugar, o arquivo modificado vai ficar assim:</p>
<script src="https://gist.github.com/gileno/e533443087a86b4a5fb5.js"></script>

<p>Para rodar este código basta utilizar o comando:</p>
<div class="highlight"><pre><span></span>scrapy crawl olx
</pre></div>


<p>Se antes usamos a opção <code>runspider</code> agora que estamos num projeto scrapy usamos a opção <code>crawl</code> passando o nome da <strong>spider</strong>, no caso <strong>olx</strong>.</p>
<p>Agora vamos modificar o método <code>parse</code> para adicionar a lógica de verificar os links para os imóveis que a página contém, após isso iremos acessar a página do imóvel para só então capturar os dados do imóvel.</p>
<script src="https://gist.github.com/gileno/b9013b0aa9b2d518fe6c.js"></script>

<p>Agora no método parse usamos <strong>xpath</strong> para percorrer a estrutura do html e encontrar todos os <strong>li</strong> que contém a <strong>class</strong> css <strong>item</strong>, cada elemento deste tipo irá ter um imóvel e assim fazemos um for para buscar o <strong>href</strong> do link único para o imóvel. Ao pegar o link de cada imóvel retornamos através do <strong>yield</strong> uma nova requisição para o scrapy realizar e passamos desta vez outro callback, o <code>parse_detail</code>. Nesse primeiro momento ele apenas vai fazer o log da url.</p>
<p>Rodando novamente o código será possível que o scrapy irá realizar 51 requisições, 1 para cada imóvel - 50 por página - e a primeira para acessar a página inicial.</p>
<div class="highlight"><pre><span></span>scrapy crawl olx
</pre></div>


<p>Após fazer a lógica de acessar cada imóvel vamos adicionar a parte de verificar se existe uma próxima página, visto que são exibidos 50 imóveis por página mas no final da página há uma paginação.</p>
<p>O código ficará assim:</p>
<script src="https://gist.github.com/gileno/39d3d663a314a56c8e2b.js"></script>

<p>Obs: Atualizei o código com a dica do <a href="https://twitter.com/eliasdorneles">Elias Dorneles</a> sobre o <strong>normalize-path</strong>, essa função do <strong>xpath</strong> serve para remover o excesso de caracteres em branco e outros caracteres que a renderização do html ignora mas que está presente no código fonte.</p>
<p>Veja que após o <code>for</code> usamos novamente o xpath para encontrar o link que contém o texto <strong>Próxima página</strong> que está no final da página do OLX - basta examinar o html. Se houver o link mandamos outra requisição ao scrapy, só que desta vez o callback é o mesmo método que estamos, o <code>parse</code>. Para acrescentar fazemos o log do título do imóvel, dando uma ideia de como podemos pegar outras informações sobre o imóvel, mais detalhes sobre isso no próximo artigo.</p>
<p>Para rodar, basta novamente enviar o comando:</p>
<div class="highlight"><pre><span></span>scrapy crawl olx
</pre></div>


<p>Para perceber que o scrapy é assíncrono nas suas requisições, basta ver que ele acessar a próxima página antes de acabar as requisições dos imóveis da primeira página.</p>
<p>Enfim, essa primeira parte fica por aqui, na próxima irei mostrar os conceitos de <strong>Item</strong> e <strong>Pipeline</strong> que o scrapy possui para capturar e processar os dados armazenados.</p>
<h3>Referências</h3>
<ul>
<li><a href="https://speakerdeck.com/eliasdorneles/explorando-scrapy-alem-do-tutorial">Explorando Scrapy além do tutorial</a></li>
<li><a href="http://doc.scrapy.org/en/1.0/index.html">Documentação Oficinal do Scrapy</a></li>
</ul>
    <div class="hline"></div>
    <div class="spacing"></div>
    <p>
        <a class="btn btn-theme" href="/tags/python" role="button" title="Tag 'python'">python</a>
        <a class="btn btn-theme" href="/tags/dados" role="button" title="Tag 'dados'">dados</a>
    </p>
    <div class="spacing"></div>
    <h6>COMPARTILHAR:</h6>
    <p class="share">
		<a target="_blank" href="https://twitter.com/home?status=Usando%20o%20Scrapy%20e%20o%20Rethinkdb%20para%20capturar%20e%20armazenar%20dados%20imobili%C3%A1rios%20-%20Parte%20I%20http%3A//www.gilenofilho.com.br/usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-i"><i class="fa fa-twitter"></i></a>
		<a href="https://www.facebook.com/sharer/sharer.php?u=http%3A//www.gilenofilho.com.br/usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-i"><i class="fa fa-facebook"></i></a>
	</p>
</article>

    <section class="row" id="comments">
        <div class="col-md-12">
            <h4>Comentários</h4>
            <div id="disqus_thread"></div>
            <script type="text/javascript">
                /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
                    var disqus_shortname = 'gilenofilho'; // required: replace example with your forum shortname
                var disqus_identifier = 'gilenofilho.com.br' + window.location.pathname;
                /* * * DON'T EDIT BELOW THIS LINE * * */
                (function () {
                    var dsq = document.createElement('script');
                    dsq.type = 'text/javascript';
                    dsq.async = true;
                    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                })();
            </script>
            <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
        </div>
    </section>
                </div>
                <div class="col-md-4">
                    <h4><a href="https://www.udemy.com/construa-um-e-commerce-com-python-3-e-django/?couponCode=websitegilenofilho">Construa um E-Commerce com Python e Django</a></h4>
                    <a href="https://www.udemy.com/construa-um-e-commerce-com-python-3-e-django/?couponCode=websitegilenofilho">
                        <img src="/images/django-udemy.jpg" alt="Construa um E-Commerce com Python e Django" class="img-responsive" />
                    </a>
    		 		<h4>Pesquisar</h4>
    		 		<div class="hline"></div>
		 			<p>
		 				<br>
                        <form class="" action="https://www.google.com/search" method="get">
                            <input name="q" type="text" class="form-control" placeholder="Pesquisar..." />
                            <input type="hidden" name="sitesearch" value="http://www.gilenofilho.com.br">
                        </form>
		 			</p>
    		 		<div class="spacing"></div>

    		 		<h4>Categorias</h4>
    		 		<div class="hline"></div>
                        <p><a href="/categorias/cursos"><i class="fa fa-angle-right"></i> cursos</a> <span class="badge badge-theme pull-right">6</span></p>
                        <p><a href="/categorias/palestras"><i class="fa fa-angle-right"></i> palestras</a> <span class="badge badge-theme pull-right">5</span></p>
                        <p><a href="/categorias/tutoriais"><i class="fa fa-angle-right"></i> tutoriais</a> <span class="badge badge-theme pull-right">12</span></p>
                        <p><a href="/categorias/utils"><i class="fa fa-angle-right"></i> utils</a> <span class="badge badge-theme pull-right">4</span></p>

    		 		<div class="spacing"></div>

    		 		<h4>Artigos Recentes</h4>
    		 		<div class="hline"></div>
					<ul class="popular-posts">
		                <li>
		                    <p><a href="/python-datasets">Bibliotecas Python para carregar Dataset's</a></p>
		                    <em>Publicado em Seg 02 janeiro 2017</em>
		                </li>
		                <li>
		                    <p><a href="/como-funciona-o-orm-do-django">Como funciona o ORM do Django</a></p>
		                    <em>Publicado em Sex 15 julho 2016</em>
		                </li>
		                <li>
		                    <p><a href="/curso-gratuito-de-django-com-python-3">Curso Gratuito de Django com Python 3</a></p>
		                    <em>Publicado em Qua 23 março 2016</em>
		                </li>
		                <li>
		                    <p><a href="/programacao-felicidade-mercado-e-outras-coisas">Programação, felicidade, mercado e outras coisas...</a></p>
		                    <em>Publicado em Ter 10 novembro 2015</em>
		                </li>
		            </ul>

    		 		<div class="spacing"></div>

    		 		<h4>Tags</h4>
    		 		<div class="hline"></div>
		 			<p>
		            	<a class="btn btn-theme" href="/tags/python" role="button">python</a>
		            	<a class="btn btn-theme" href="/tags/dados" role="button">dados</a>
		            	<a class="btn btn-theme" href="/tags/django" role="button">django</a>
		            	<a class="btn btn-theme" href="/tags/database" role="button">database</a>
		            	<a class="btn btn-theme" href="/tags/video-aula" role="button">video-aula</a>
		            	<a class="btn btn-theme" href="/tags/lifestyle" role="button">lifestyle</a>
		            	<a class="btn btn-theme" href="/tags/comunidade" role="button">comunidade</a>
		            	<a class="btn btn-theme" href="/tags/startup" role="button">startup</a>
		            	<a class="btn btn-theme" href="/tags/design" role="button">design</a>
		            	<a class="btn btn-theme" href="/tags/inteligencia-artificial" role="button">inteligência-artificial</a>
		            	<a class="btn btn-theme" href="/tags/universidade" role="button">universidade</a>
		            	<a class="btn btn-theme" href="/tags/pythonbrasil" role="button">pythonbrasil</a>
		            	<a class="btn btn-theme" href="/tags/engenharia-de-avaliacoes" role="button">engenharia-de-avaliações</a>
		            	<a class="btn btn-theme" href="/tags/deploy" role="button">deploy</a>
		            	<a class="btn btn-theme" href="/tags/evento" role="button">evento</a>
		 			</p>
                </div>
            </div>

            <!-- Footer -->
<div id="footerwrap">
   <div class="container">
       <div class="row">
           <div class="col-md-6">
               <h4>Sobre</h4>
               <div class="hline-w"></div>
               <p>
    Website e Blog de Gileno Filho, escrevo sobre: Desenvolvimento,
    Python, Django, Ciência de Dados, Engenharia de Avaliações,
    Inteligência Artificial e Design Minimalista.
</p>
           </div>
           <div class="col-md-6">
               <h4>Social</h4>
               <div class="hline-w"></div>
               <p>
                   <a class="white-text" href="https://github.com/gileno" title="GitHub">
                       <i class="fa fa-github"></i>
                   </a>
                   <a class="white-text" href="https://twitter.com/gilenofilho" title="Twitter">
                       <i class="fa fa-twitter"></i>
                   </a>
                   <a class="white-text" href="https://www.facebook.com/gilenofilho" title="Facebook">
                       <i class="fa fa-facebook"></i>
                   </a>
                   <a class="white-text" href="mailto:contato@gilenofilho.com.br" title="E-mail">
                       <i class="fa fa-envelope"></i>
                   </a>
               </p>
           </div>
       </div>
   </div>
</div>
            <!-- Scripts -->
            <script   src="https://code.jquery.com/jquery-2.2.4.min.js"   integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>
            <script src="/theme/js/bootstrap.min.js"></script>
        </main>
    </body>
</html>