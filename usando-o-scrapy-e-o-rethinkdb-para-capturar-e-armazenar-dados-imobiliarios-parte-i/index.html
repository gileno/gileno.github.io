<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Usando o Scrapy e o Rethinkdb para capturar e armazenar dados imobiliários - Parte I</title>
  <meta name="description" content="Introdução">
  
  <meta name="author" content="Gileno Filho">
  <meta name="copyright" content="&copy; Gileno Filho 2015">
  

  <!-- External libraries -->
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/styles/monokai_sublime.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.7.1/css/lightbox.css">

  <!-- Favicon and other icons (made with http://www.favicon-generator.org/) -->
  <link rel="shortcut icon" href="/assets/icons/favicon.ico" type="image/x-icon">
	<link rel="icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="apple-touch-icon" sizes="57x57" href="/assets/icons/apple-icon-57x57.png">
	<link rel="apple-touch-icon" sizes="60x60" href="/assets/icons/apple-icon-60x60.png">
	<link rel="apple-touch-icon" sizes="72x72" href="/assets/icons/apple-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="76x76" href="/assets/icons/apple-icon-76x76.png">
	<link rel="apple-touch-icon" sizes="114x114" href="/assets/icons/apple-icon-114x114.png">
	<link rel="apple-touch-icon" sizes="120x120" href="/assets/icons/apple-icon-120x120.png">
	<link rel="apple-touch-icon" sizes="144x144" href="/assets/icons/apple-icon-144x144.png">
	<link rel="apple-touch-icon" sizes="152x152" href="/assets/icons/apple-icon-152x152.png">
	<link rel="apple-touch-icon" sizes="180x180" href="/assets/icons/apple-icon-180x180.png">
	<link rel="icon" type="image/png" sizes="192x192"  href="/assets/icons/android-icon-192x192.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/assets/icons/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="96x96" href="/assets/icons/favicon-96x96.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/assets/icons/favicon-16x16.png">
	<link rel="manifest" href="/assets/icons/manifest.json">
	<meta name="msapplication-TileColor" content="#ffffff">
	<meta name="msapplication-TileImage" content="/assets/icons/ms-icon-144x144.png">
	<meta name="theme-color" content="#ffffff">

	<!-- Facebook OGP cards -->
  <meta property="og:description" content="Introdução" />
  <meta property="og:url" content="http://www.gilenofilho.com.br" />
  <meta property="og:site_name" content="Gileno Filho" />
  <meta property="og:title" content="Usando o Scrapy e o Rethinkdb para capturar e armazenar dados imobiliários - Parte I" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="http://www.gilenofilho.com.br/assets/eu2-thumb.png" />
  <meta property="og:image:type" content="image/png" />
  <meta property="og:image:width" content="612" />
  <meta property="og:image:height" content="605" />

  <!-- Twitter: card tags -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Usando o Scrapy e o Rethinkdb para capturar e armazenar dados imobiliários - Parte I">
  <meta name="twitter:description" content="Introdução">
  <meta name="twitter:image" content="http://www.gilenofilho.com.br/assets/eu2-thumb.png">
  <meta name="twitter:url" content="http://www.gilenofilho.com.br">

  

	<!-- Site styles -->
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://www.gilenofilho.com.br//usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-i">
  <link rel="alternate" type="application/rss+xml" title="Gileno Filho" href="http://www.gilenofilho.com.br//feed.xml" />
</head>


  <body>

    <header class="navigation" role="banner">
  <div class="navigation-wrapper">
    <a href="/" class="logo">
    	
      <span>Gileno Filho</span>
      
    </a>
    <a href="javascript:void(0)" class="navigation-menu-button" id="js-mobile-menu">
    	<i class="fa fa-bars"></i>
    </a>
    <nav role="navigation">
      <ul id="js-navigation-menu" class="navigation-menu show">
        <li class="nav-link"><a href="/categoria/cursos/">Cursos</a></li>
      	
            
            <li class="nav-link"><a href="/artigos/">Artigos</a>
            
        
            
        
            
        
            
        
            
        
            
        
            
            <li class="nav-link"><a href="/sobre/">Sobre</a>
            
        
            
        
            
        
            
        
            
        
      </ul>
    </nav>
  </div>
</header>


    <div class="page-content">
        <div class="post">

<div class="post-header-container " >
	<div class="scrim ">
		<header class="post-header">
		  <h1 class="title">Usando o Scrapy e o Rethinkdb para capturar e armazenar dados imobiliários - Parte I</h1>
		  <p class="info">por <strong>Gileno Filho</strong></p>
		</header>
	</div>
</div>

<div class="wrapper">

 <span class="page-divider">
  <span class="one"></span>
  <span class="two"></span>
</span>
 

<section class="post-meta">
	<div class="post-date">June 25, 2015</div>
	<div class="post-categories">
	in 
	  
		<a href="/category/tutoriais">Tutoriais</a>
	  
	
	</div>
</section>

<article class="post-content">
  <h3 id="introduo">Introdução</h3>

<p>Olá pessoal, a algum tempo que estou organizando minha agenda para voltar a trabalhar em alguns <a href="https://pt.wikipedia.org/wiki/Web_crawler">Web Crawlers</a> para capturar dados imobiliários que é um tipo de dado que gosto de trabalhar. Assim resolvi publicar esse artigo, que fará parte de uma série de 3, onde irei mostrar como fazer um crawler usando o <a href="http://scrapy.org/">Scrapy</a> e como armazenar num banco de dados que muito me interessa, o <a href="http://www.rethinkdb.com/">rethinkdb</a>.</p>

<h3 id="agenda">Agenda</h3>

<ul>
  <li><a href="http://gilenofilho.com.br/usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-i/">Parte I - Configurando e rodando o Scrapy</a></li>
  <li><a href="http://gilenofilho.com.br/usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-ii/">Parte II - Instalando, configurando e armazenando os dados no Rethinkdb</a></li>
  <li><a href="http://gilenofilho.com.br/usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-iii/">Parte III - Deploy do projeto Scrapy</a></li>
</ul>

<h3 id="vamos-l">Vamos lá</h3>

<p>O Scrapy é um framework para facilitar o desenvolvimento de crawlers, pois mesmo sendo fácil fazer um crawler usando o built-in do Python como o <a href="https://docs.python.org/2/library/urllib.html">urllib</a>, ou bibliotecas externas como <a href="http://docs.python-requests.org/en/latest/">requests</a>, fica mais rápido e prático utilizar um conjunto de ferramentas desenhados para este fim, é o famoso “batteries included”.</p>

<p>Para instalar o Scrapy vamos utilizar o pip (supondo que já esteja num <a href="https://virtualenv.pypa.io/en/latest/">virtualenv</a>):</p>

<div class="highlight"><pre><code class="language-sh" data-lang="sh">pip install scrapy</code></pre></div>

<p>Após instalar o scrapy você terá disponível o comando “scrapy” mais detalhes sobre as opções dele aqui:</p>

<p>http://doc.scrapy.org/en/1.0/topics/commands.html</p>

<p>O scrapy é composto de “spiders” que é a parte do código que irá definir que páginas serão acessadas para capturar informações, “items” que são as informações que serão extraídas das páginas e os “pipelines” que irão definir como esses “items” serão processados.</p>

<p>Um exemplo simples de um crawler utilizando o Scrapy:</p>

<script src="https://gist.github.com/gileno/8579ef62f5a700ca99d4.js"></script>

<p>Para rodar basta utilizar o comando scrapy:</p>

<div class="highlight"><pre><code class="language-sh" data-lang="sh">scrapy runspider gilenofilho.py</code></pre></div>

<p>Você verá algo assim:</p>

<div class="highlight"><pre><code class="language-sh" data-lang="sh">...
2015-06-22 18:26:07 <span class="o">[</span>scrapy<span class="o">]</span> DEBUG: Redirecting <span class="o">(</span>301<span class="o">)</span> to &lt;GET http://gilenofilho.com.br/&gt; from &lt;GET http://www.gilenofilho.com.br/&gt;
2015-06-22 18:26:07 <span class="o">[</span>scrapy<span class="o">]</span> DEBUG: Crawled <span class="o">(</span>200<span class="o">)</span> &lt;GET http://gilenofilho.com.br/&gt; <span class="o">(</span>referer: None<span class="o">)</span>
2015-06-22 18:26:07 <span class="o">[</span>gilenofilho<span class="o">]</span> DEBUG: Hello World: http://gilenofilho.com.br/
2015-06-22 18:26:07 <span class="o">[</span>scrapy<span class="o">]</span> INFO: Closing spider <span class="o">(</span>finished<span class="o">)</span>
2015-06-22 18:26:07 <span class="o">[</span>scrapy<span class="o">]</span> INFO: Dumping Scrapy stats:
...</code></pre></div>

<p>Uma Spider é basicamente uma classe que herda de <code>scrapy.Spider</code> o atributo <code>start_urls</code> está definindo as urls que devem ser acessadas inicialmente, você pode definir um método <code>starts_requests</code> que deve retornar uma lista de <code>scrapy.Request</code> através da keyword <code>yield</code>, assim:</p>

<p>Obs: a implementação padrão do <code>starts_requests</code> procura o atributo <code>start_urls</code> e chama o método <code>parse</code>.</p>

<script src="https://gist.github.com/gileno/83720a8c73a52685e399.js"></script>

<p>Deve se utilizar <code>yield</code> e passar um <strong>callback</strong> para a <code>scrapy.Request</code> pois o scrapy faz requisições assíncronas, isto é, não espera a requisição inicial acabar para fazer uma nova requisição, e desta forma utiliza o conceito de geradores em Python, você pode ver mais detalhes de como geradores funcionam acessando as palestras de Luciano Ramalho em: http://pt.slideshare.net/ramalho/.</p>

<p>O scrapy tem o conceito de projeto onde ficam organizados as “Spiders”, “items” e “pipelines”. Para criar um projeto scrapy basta utilizar o comando:</p>

<div class="highlight"><pre><code class="language-sh" data-lang="sh">scrapy startproject nome_do_projeto</code></pre></div>

<p>Você verá que uma estrutura de diretórios e arquivos será criada para que facilite o crescimento do seu crawler. Eu criei um projeto chamado <strong>scrapy_olx</strong> e meu sistema de diretórios ficou assim:</p>

<div class="highlight"><pre><code class="language-sh" data-lang="sh">scrapy_olx
- scrapy_olx
- - spiders
- - - __init__.py
- - __init__.py
- - items.py
- - pipelines.py
- - settings.py
- scrapy.cfg</code></pre></div>

<p>Agora vamos criar nosso primeiro Spider, com o comando:</p>

<div class="highlight"><pre><code class="language-sh" data-lang="sh">scrapy genspider olx pe.olx.com.br</code></pre></div>

<p>Estou criando um crawler para capturar os imóveis de Pernambuco (PE) e esta é a url inicial no OLX. Dentro do diretório <strong>spiders</strong> foi criado um arquivo chamado olx.py contendo o esqueleto do nosso código, vou modificar o <strong>starts_urls</strong> para começar com a url dos imóveis para alugar, o arquivo modificado vai ficar assim:</p>

<script src="https://gist.github.com/gileno/e533443087a86b4a5fb5.js"></script>

<p>Para rodar este código basta utilizar o comando:</p>

<div class="highlight"><pre><code class="language-sh" data-lang="sh">scrapy crawl olx</code></pre></div>

<p>Se antes usamos a opção <code>runspider</code> agora que estamos num projeto scrapy usamos a opção <code>crawl</code> passando o nome da <strong>spider</strong>, no caso <strong>olx</strong>.</p>

<p>Agora vamos modificar o método <code>parse</code> para adicionar a lógica de verificar os links para os imóveis que a página contém, após isso iremos acessar a página do imóvel para só então capturar os dados do imóvel.</p>

<script src="https://gist.github.com/gileno/b9013b0aa9b2d518fe6c.js"></script>

<p>Agora no método parse usamos <strong>xpath</strong> para percorrer a estrutura do html e encontrar todos os <strong>li</strong> que contém a <strong>class</strong> css <strong>item</strong>, cada elemento deste tipo irá ter um imóvel e assim fazemos um for para buscar o <strong>href</strong> do link único para o imóvel. Ao pegar o link de cada imóvel retornamos através do <strong>yield</strong> uma nova requisição para o scrapy realizar e passamos desta vez outro callback, o <code>parse_detail</code>. Nesse primeiro momento ele apenas vai fazer o log da url.</p>

<p>Rodando novamente o código será possível que o scrapy irá realizar 51 requisições, 1 para cada imóvel - 50 por página - e a primeira para acessar a página inicial.</p>

<div class="highlight"><pre><code class="language-sh" data-lang="sh">scrapy crawl olx</code></pre></div>

<p>Após fazer a lógica de acessar cada imóvel vamos adicionar a parte de verificar se existe uma próxima página, visto que são exibidos 50 imóveis por página mas no final da página há uma paginação.</p>

<p>O código ficará assim:</p>

<script src="https://gist.github.com/gileno/39d3d663a314a56c8e2b.js"></script>

<p>Obs: Atualizei o código com a dica do <a href="https://twitter.com/eliasdorneles">Elias Dorneles</a> sobre o <strong>normalize-path</strong>, essa função do <strong>xpath</strong> serve para remover o excesso de caracteres em branco e outros caracteres que a renderização do html ignora mas que está presente no código fonte.</p>

<p>Veja que após o <code>for</code> usamos novamente o xpath para encontrar o link que contém o texto <strong>Próxima página</strong> que está no final da página do OLX - basta examinar o html. Se houver o link mandamos outra requisição ao scrapy, só que desta vez o callback é o mesmo método que estamos, o <code>parse</code>. Para acrescentar fazemos o log do título do imóvel, dando uma ideia de como podemos pegar outras informações sobre o imóvel, mais detalhes sobre isso no próximo artigo.</p>

<p>Para rodar, basta novamente enviar o comando:</p>

<div class="highlight"><pre><code class="language-sh" data-lang="sh">scrapy crawl olx</code></pre></div>

<p>Para perceber que o scrapy é assíncrono nas suas requisições, basta ver que ele acessar a próxima página antes de acabar as requisições dos imóveis da primeira página.</p>

<p>Enfim, essa primeira parte fica por aqui, na próxima irei mostrar os conceitos de <strong>Item</strong> e <strong>Pipeline</strong> que o scrapy possui para capturar e processar os dados armazenados.</p>

<h3 id="referncias">Referências</h3>

<ul>
  <li><a href="https://speakerdeck.com/eliasdorneles/explorando-scrapy-alem-do-tutorial">Explorando Scrapy além do tutorial</a></li>
  <li><a href="http://doc.scrapy.org/en/1.0/index.html">Documentação Oficinal do Scrapy</a></li>
</ul>

</article>



<section class="tags">
	<strong>Tags:</strong> <a href="/tag/python">python</a>,&nbsp;<a href="/tag/dados">dados</a>
</section>



<section class="rss">
	<p class="rss-subscribe text"><strong>Inscreva-se <a href="/feed.xml">via RSS</a></strong></p>
</section>

<section class="share">
  <span>Compartilhar: </span>
  
  	
  		<a href="//twitter.com/share?text=Usando+o+Scrapy+e+o+Rethinkdb+para+capturar+e+armazenar+dados+imobili%C3%A1rios+-+Parte+I&url=http://www.gilenofilho.com.br//usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-i.html&via=GilenoFilho"
  			onclick="window.open(this.href, 'twitter-share', 'width=550,height=255');return false;">
  			<i class="fa fa-twitter-square fa-lg"></i>
  		</a>
  	
  	
  	
  	
  	
  
  	
  	
  	
  	
  	
  
  	
  	
  	
  	
  		<a href="//www.linkedin.com/shareArticle?mini=true&url=http://www.gilenofilho.com.br//usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-i.html"
  			onclick="window.open(this.href, 'linkedin-share', 'width=550,height=255');return false;">
  			<i class="fa fa-linkedin-square fa-lg"></i>
  		</a>
  	
  	
  
  	
  	
  	
  	
  	
  
</section>



<section class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_shortname = 'gilenofilho';
	var disqus_identifier = 'gilenofilho.com.br' + window.location.pathname;
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>



</div>
</div>

    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h3 class="footer-heading">Gileno Filho</h3>

    <div class="site-navigation">

    	<p><strong>Links</strong></p>
      <ul class="pages">
        
        
          <li class="nav-link"><a href="/artigos/">Artigos</a>
        
        
        
        
        
        
        
        
        
        
        
        
        
          <li class="nav-link"><a href="/sobre/">Sobre</a>
        
        
        
        
        
        
        
        
        
        
            <li class="nav-link">
                <a href="/feed.xml">RSS</a>
            </li>
      </ul>
    </div>

    <div class="site-contact">

    	<p><strong>Contato</strong></p>
      <ul class="social-media-list">
      	<li>
      		<a href="mailto:contato@gilenofilho.com.br">
	      		<i class="fa fa-envelope-o"></i>
	      		<span class="username">contato@gilenofilho.com.br</span>
      		</a>
      	</li>

      	
	      	
	      	<li>
	          <a href="https://twitter.com/gilenofilho" title="Follow me on Twitter">
	            <i class="fa fa-twitter"></i>
	            <span class="username">GilenoFilho</span>
	          </a>
	        </li>
	      	
      	
	      	
	      	<li>
	          <a href="https://github.com/gileno" title="Fork me on GitHub">
	            <i class="fa fa-github"></i>
	            <span class="username">gileno</span>
	          </a>
	        </li>
	      	
      	
	      	
	      	<li>
	          <a href="https://br.linkedin.com/in/gilenofilho" title="Connect with me on LinkedIn">
	            <i class="fa fa-linkedin"></i>
	            <span class="username">Gileno Filho</span>
	          </a>
	        </li>
	      	
      	
	      	
	      	<li>
	          <a href="https://www.youtube.com/channel/UCThem2-TpI1kJoNqf_hFZOQ" title="Subscribe on YouTube">
	            <i class="fa fa-youtube"></i>
	            <span class="username">Gileno Filho</span>
	          </a>
	        </li>
	      	
      	

      </ul>
    </div>

    <div class="site-signature">
    	<p class="rss-subscribe text">
            <strong>Inscreva-se</strong>
            <form action="//gilenofilho.us11.list-manage.com/subscribe/post?u=42028a9587ab7791c65804500&amp;id=cf58dbb2d8" method="post">
                <input type="text" name="EMAIL" value="" placeholder="Email" />
            </form>
        </p>
      <p class="text">Cursos, tutoriais e palestras sobre o mundo de ciência e tecnologia</p>
    </div>

  </div>

</footer>

<!-- Scripts -->
<script src="//code.jquery.com/jquery-1.11.2.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/highlight.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.7.1/js/lightbox.min.js"></script>
<script>

$(document).ready(function() {

	// Syntax highlighting
	hljs.initHighlightingOnLoad();

	// Header
  var menuToggle = $('#js-mobile-menu').unbind();
  $('#js-navigation-menu').removeClass("show");
  menuToggle.on('click', function(e) {
    e.preventDefault();
    $('#js-navigation-menu').slideToggle(function(){
      if($('#js-navigation-menu').is(':hidden')) {
        $('#js-navigation-menu').removeAttr('style');
      }
    });
  });


});

</script>


<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-15015773-2', 'auto');
  ga('send', 'pageview', {
  	'page': '/usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-i',
  	'title': 'Usando o Scrapy e o Rethinkdb para capturar e armazenar dados imobiliários - Parte I'
  });
</script>



  </body>

</html>
