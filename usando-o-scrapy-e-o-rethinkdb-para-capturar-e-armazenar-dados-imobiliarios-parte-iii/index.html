<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml"
    itemscope itemtype="http://schema.org/Blog"
    lang="pt">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0"/>
        <meta http-equiv="content-language" content="pt-br">
        <meta name="robots" content="index, follow">
        <meta name="description" content="Website Gileno Filho"/>
        <meta name="keywords" content="programação, python, recife, desenvolvimento, data science"/>
        <meta name="author" content="Gileno Filho">
        <meta name="generator" content="Pelican">
        <title>Usando o Scrapy e o Rethinkdb para capturar e armazenar dados imobiliários - Parte III | Gileno Filho</title>

        <!-- Feeds -->
            <link href="http://www.gilenofilho.com.br/feeds.atom" type="application/atom+xml" rel="alternate" title="Gileno Filho ATOM Feed"/>
            <link href="http://www.gilenofilho.com.br/feeds.rss" type="application/rss+xml" rel="alternate" title="Gileno Filho RSS Feed"/>

        <!-- CSS  -->
        <link rel="stylesheet" href="/theme/css/font-awesome.min.css">
        <link href="/theme/css/bootstrap.css" type="text/css" rel="stylesheet" />
        <link href="/theme/css/style.css" type="text/css" rel="stylesheet" />
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
          <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
        <![endif]-->

<link href="/theme/css/pygments.css" type="text/css" rel="stylesheet" media="screen,projection"/>
        <!-- Metadata -->
    <!-- OpenGraph -->
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Usando o Scrapy e o Rethinkdb para capturar e armazenar dados imobiliários - Parte III"/>
    <meta property="og:url" content="http://www.gilenofilho.com.br/usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-iii"/>
    <meta property="og:site_name" content="Gileno Filho"/>
    <meta property="og:description" content="Introdução Olá pessoal, esta é a parte III da série sobre o Scrapy, abaixo os links para todos os artigos da série: Parte I - Configurando e..."/>
    <meta property="og:image" content="http://www.gilenofilho.com.brimages/eu.jpg"/>

    <!-- Twitter -->
    <meta name="twitter:card" content="summary"/>
    <meta name="twitter:site" content="@gilenofilho"/>
    <meta name="twitter:creator" content="@gilenofilho"/>
    <meta name="twitter:domain" content="www.gilenofilho.com.br"/>
    <meta name="twitter:title" content="Usando o Scrapy e o Rethinkdb para capturar e armazenar dados imobiliários - Parte III"/>
    <meta name="twitter:description" content="Introdução Olá pessoal, esta é a parte III da série sobre o Scrapy, abaixo os links para todos os artigos da série: Parte I - Configurando e..."/>
    <meta name="twitter:image:src" content="http://www.gilenofilho.com.brimages/eu.jpg"/>

    <!-- Article meta -->
    <meta property="article:author" content="Gileno Filho"/>
    <meta property="article:section" content="tutoriais"/>
    <meta property="article:tag" content="python, dados"/>
    <meta property="article:published_time" content="2015-09-08T13:33:00-03:00"/>

    <!-- Google+ -->
    <meta itemprop="name" content="Usando o Scrapy e o Rethinkdb para capturar e armazenar dados imobiliários - Parte III"/>
    <meta itemprop="description" content="Introdução Olá pessoal, esta é a parte III da série sobre o Scrapy, abaixo os links para todos os artigos da série: Parte I - Configurando e..."/>
    <meta itemprop="image" content="http://www.gilenofilho.com.brimages/eu.jpg"/>

    <!-- General purpose meta -->
    <meta name="description" content="Introdução Olá pessoal, esta é a parte III da série sobre o Scrapy, abaixo os links para todos os artigos da série: Parte I - Configurando e..."/>
    <meta name="keywords" content="python, dados"/>

        <!-- Google Analytics -->
        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
          ga('create', 'UA-15015773-2', 'auto');
          ga('send', 'pageview');
        </script>

    </head>

    <body>
        <header>
<!-- Fixed navbar -->
<div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/">Gileno Filho</a>
    </div>
    <div class="navbar-collapse collapse navbar-right">
      <ul class="nav navbar-nav">
        <li><a href="/">Início</a></li>
          <li ><a href="/sobre">Sobre</a></li>
          <li ><a href="/categorias/cursos/">Cursos</a></li>
          <li ><a href="/categorias/palestras/">Palestas</a></li>
          <li ><a href="/categorias/tutoriais/">Tutoriais</a></li>
          <li ><a href="/categorias/utils/">Utils</a></li>
      </ul>
    </div><!--/.nav-collapse -->
  </div>
</div>            <div id="blue">
                <div class="container">
                    <div class="row">
                        <h3>
    programador, cientista, pythonista e minimalista. Recife, Brasil
</h3>
                    </div><!-- /row -->
                </div> <!-- /container -->
            </div><!-- /blue -->
        </header>
        <main>
            <!-- Content -->
            <div class="container mtb">
                <div class="col-md-8">

<ol class="breadcrumb">
    <li>
    <a title="Gileno Filho Home" href="/"><i class="fa fa-home pr-10"></i> Início</a>
    </li>
        <li>
        <a title="tutoriais|escape" href="/categorias/tutoriais">tutoriais</a>
        </li>
        <li>Usando o Scrapy e o Rethinkdb para capturar e armazenar dados imobiliários - Parte III</li>
</ol><article>
    <a href="/usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-iii"><h3 class="ctitle">Usando o Scrapy e o Rethinkdb para capturar e armazenar dados imobiliários - Parte III</h3></a>
    <p>
        Publicado em:  <time datetime="2015-09-08T13:33:00-03:00">Ter 08 setembro 2015</time>.
        |
        Por: <a href="/autores/gileno-filho">Gileno Filho</a>
        |
        Arquivado em: <a href="/categorias/tutoriais">tutoriais</a>
    </p>
    <h3>Introdução</h3>
<p>Olá pessoal, esta é a parte III da série sobre o Scrapy, abaixo os links para todos os artigos da série:</p>
<ul>
<li><a href="http://gilenofilho.com.br/usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-i/">Parte I - Configurando e rodando o Scrapy</a></li>
<li><a href="http://gilenofilho.com.br/usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-ii/">Parte II - Instalando, configurando e armazenando os dados no Rethinkdb</a></li>
<li><a href="http://gilenofilho.com.br/usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-iii/">Parte III - Deploy do projeto Scrapy</a></li>
</ul>
<p>Nos artigos anteriores mostrei como capturar os dados imobiliários do site OLX usando o scrapy e depois como armazenar em um banco de dados, no caso em questão usamos o <a href="http://www.rethinkdb.com/">Rethinkdb</a>.</p>
<h3>Vamos lá</h3>
<p>Agora iremos ver como colocar o nosso projeto Scrapy para rodar em um servidor na nuvem, pois quando você está fazendo um crawler um pouco maior que leva mais tempo para capturar as informações fica inviável deixar ele rodando na sua máquina já que você pode querer desligá-la, reiniciá-la ou pode simplesmente deixar em espera o que iria interromper o processamento.</p>
<p>Existem algumas formas de se colocar um projeto scrapy em um <a href="https://pt.wikipedia.org/wiki/Servidor_virtual_privado">VPS</a>, vou listar algumas:</p>
<ul>
<li>Crontab</li>
<li>Supervisor</li>
<li>Scrapyd</li>
<li>Scrapinghub</li>
</ul>
<p>Por hora eu irei fazer apenas uma pequena apresentação de todas essas opções expandindo apenas a Scrapyd, futuramente irei gravar um vídeo mostrando como utilizar as opções do crontab e supervisor.</p>
<h4>Crontab</h4>
<p>O <a href="https://pt.wikipedia.org/wiki/Crontab">crontab</a> é um utilitário de sistemas Unix que gerencia comandos que precisam ser executados com alguma periodicidade, assim basta acessar um VPS via ssh, baixar o seu código, instalar as dependências - realizar os passos iniciais presentes nos artigos anteriores - e depois adicionar a tarefa de acordo com o padrão que o crontab aceita (veja o link do <a href="https://pt.wikipedia.org/wiki/Crontab">crontab</a>).</p>
<h4>Supervisor</h4>
<p>O <a href="http://supervisord.org/">Supervisor</a> é um sistema desenvolvido em Python que controla a execução de processos. Eu utilizo ele bastante em meus projetos, pois com ele eu tenho como organizar a execução de processos indicando o usuário que irá executar, o diretório de acesso, controle de log e via linha de comando posso iniciar ou terminar o processo de maneira bem simples.</p>
<h4>Scrapinghub</h4>
<p><a href="http://scrapinghub.com/">Scrapinghub</a> é a empresa por trás do Scrapy, e essa plataforma dá a possibilidade de você fazer o deploy facilitado de seus crawlers que utilizam o Scrapy, além de visualizar as estatísticas e os dados gerados pelos crawlers.</p>
<h4>Scrapyd</h4>
<p>O <a href="http://scrapyd.readthedocs.org/en/latest/index.html">Scrapyd</a> é uma aplicação que fornece uma API REST em que você pode fazer upload de seus projetos além de iniciar ou parar a execução de crawlers presentes no seu projeto.</p>
<p>Para utilizar o Scrapyd eu recomendo acessar a sua máquina VPS e em seguida baixar e instalar o Scrapyd.</p>
<p>Considerando que já está no terminal do seu VPS, faça:</p>
<p>Obs1: você pode criar um virtualenv ou se preferir instalar globalmente verifique se está acessando com o usuário <strong>root</strong> ou no grupo <strong>sudo</strong>.
Obs2: linhas com o caractere "$" são comandos executados, linhas sem esse caractere é a saída esperada.</p>
<div class="highlight"><pre><span></span>$ <span class="nb">cd</span> /caminho/no/vps/para/o/projeto
$ pip install scrapyd
</pre></div>


<p>Após a instalação do scrapyd, um novo comando estará disponível:</p>
<div class="highlight"><pre><span></span>$ scrapyd
<span class="m">2015</span>-09-07 <span class="m">20</span>:55:03-0400 <span class="o">[</span>-<span class="o">]</span> Log opened.
<span class="m">2015</span>-09-07 <span class="m">20</span>:55:03-0400 <span class="o">[</span>-<span class="o">]</span> twistd <span class="m">15</span>.2.1 <span class="o">(</span>/usr/bin/python <span class="m">2</span>.7.6<span class="o">)</span> starting up.
<span class="m">2015</span>-09-07 <span class="m">20</span>:55:03-0400 <span class="o">[</span>-<span class="o">]</span> reactor class: twisted.internet.epollreactor.EPollReactor.
<span class="m">2015</span>-09-07 <span class="m">20</span>:55:03-0400 <span class="o">[</span>-<span class="o">]</span> Site starting on <span class="m">6800</span>
<span class="m">2015</span>-09-07 <span class="m">20</span>:55:03-0400 <span class="o">[</span>-<span class="o">]</span> Starting factory &lt;twisted.web.server.Site instance at 0x7f883b0adb48&gt;
<span class="m">2015</span>-09-07 <span class="m">20</span>:55:03-0400 <span class="o">[</span>Launcher<span class="o">]</span> Scrapyd <span class="m">1</span>.0.2 started: <span class="nv">max_proc</span><span class="o">=</span><span class="m">4</span>, <span class="nv">runner</span><span class="o">=</span><span class="s1">&#39;scrapyd.runner&#39;</span>
</pre></div>


<p>Ao rodar este comando você verá que ele irá ativar um servidor web na porta 6800, entretanto você não vai querer rodar o servidor dessa forma, você irá precisar colocar ele em modo daemon para que possa realizar outras atividades e deixá-lo rodando. Como estou acostumado com o supervisor, utilizei ele para monitorar e iniciar o processo do scrapyd - nesse caso ele não vai rodar o crawler em específico, vai rodar o scrapyd e este vai ser responsável pela execução dos crawlers.</p>
<p>Para esse experimento estou utilizando uma máquina com Ubuntu, assim posso instalar o Supervisor dessa forma:</p>
<div class="highlight"><pre><span></span>$ apt-get install supervisor
</pre></div>


<p>Caso utilize outra distribuição Linux procure os pacotes relacionados ao Supervisor ou instale via pip:</p>
<p>http://supervisord.org/installing.html#installing-via-pip</p>
<p>Quando instalado via gerenciador de pacotes da distribuição ele já é executado assim que iniciar a máquina, assim basta criar um arquivo de configuração para o processo relativo ao Scrapyd:</p>
<div class="highlight"><pre><span></span>$ <span class="nb">cd</span> /etc/supervisor/conf.d/
$ vi scrapyd.conf
</pre></div>


<p>Em seguida coloque o seguinte conteúdo no arquivo <strong>scrapyd.conf</strong>:</p>
<div class="highlight"><pre><span></span><span class="k">[program:scrapyd]</span>
<span class="na">command</span><span class="o">=</span><span class="s">scrapyd</span>
<span class="na">user</span><span class="o">=</span><span class="s">root</span>
<span class="na">autostart</span><span class="o">=</span><span class="s">true</span>
</pre></div>


<p>Não é recomendado utilizar o usuário root mas para fins de teste irei indicar este usuário, mas lembre-se de criar um usuário para o scrapyd quando for colocar em produção.</p>
<p>A parte <code>[program:scrapyd]</code> indica o nome do programa, vai ser útil na hora de iniciar ou para o processo, o <code>command=scrapyd</code> é o comando que irá ser executado, caso esteja utilizando um virtualenv será preciso indicar o caminho do script <strong>scrapyd</strong> relativo ao virtualenv. O <code>user=root</code> indica que usuário irá rodar o comando e a opção <code>autorestart=true</code> serve para reiniciar o processo sempre que ele "cair", independente do que aconteceu, mais detalhes em:</p>
<p>http://supervisord.org/configuration.html</p>
<p>Agora para ativar o scrapyd iremos executar o comando:</p>
<div class="highlight"><pre><span></span>$ supervisorctl reread
scrapyd: available
$ supervisorctl reload
Restarted supervisord
$ upervisorctl status
scrapyd       RUNNING    pid <span class="m">1382</span>, uptime <span class="m">0</span>:00:15
</pre></div>


<p>Agora já podemos acessar a interface web fornecida pelo scrapyd, basta ir no navegador e digitar:</p>
<p>http://&#60;IP-DO-VPS&#62;:6800/</p>
<p>Se tudo deu certo, você verá uma interface extremamente simples, agora saia do VPS e volte a trabalhar localmente.</p>
<p>Acessando a basta do projeto localmente - com o virtualenv ativado caso esteja utilizando, instale:</p>
<div class="highlight"><pre><span></span>$ pip install scrapyd-client
</pre></div>


<p>Com esse pacote iremos ter um facilitador para o deploy do nosso projeto no servidor onde está o scrapyd, pois o scrapyd fornece uma API REST para fazer upload do nosso projeto no formato <a href="https://wiki.python.org/moin/egg">EGG</a>. O scrapyd-client fornece um comando <code>scrapyd-deploy</code> que facilita essa geração do egg e em seguida upload para o servidor, assim no arquivo <strong>scrapy.cfg</strong> do seu projeto adicione no final (ou substitua caso já tenha algum valor para a configuração <strong>deploy</strong>):</p>
<div class="highlight"><pre><span></span><span class="k">[deploy]</span>
<span class="na">url</span> <span class="o">=</span> <span class="s">http://&lt;IP-DO-VPS&gt;:6800/</span>
<span class="na">username</span> <span class="o">=</span> <span class="s">root</span>
<span class="na">password</span> <span class="o">=</span> <span class="s">&lt;senha&gt;</span>
</pre></div>


<p>Em seguida faça o deploy do seu projeto:</p>
<div class="highlight"><pre><span></span>$ scrapyd-deploy -p &lt;nome-do-projeto&gt;
Packing version <span class="m">1441674561</span>
Deploying to project <span class="s2">&quot;&lt;nome-do-projeto&gt;&quot;</span> in http://&lt;IP-DO-VPS&gt;:6800/addversion.json
Server response <span class="o">(</span><span class="m">200</span><span class="o">)</span>:
<span class="o">{</span><span class="s2">&quot;status&quot;</span>: <span class="s2">&quot;ok&quot;</span>, <span class="s2">&quot;project&quot;</span>: <span class="s2">&quot;&lt;nome-do-projeto&gt;&quot;</span>, <span class="s2">&quot;version&quot;</span>: <span class="s2">&quot;1441674561&quot;</span>, <span class="s2">&quot;spiders&quot;</span>: <span class="m">2</span>, <span class="s2">&quot;node_name&quot;</span>: <span class="s2">&quot;&lt;nome-do-servidor&gt;&quot;</span><span class="o">}</span>
</pre></div>


<p>Obs: No exemplo da série o nome do projeto é <strong>scrapy_olx</strong>.</p>
<p>Agora você já pode colocar um crawler para rodar, para isso é preciso acessar a API REST do Scrapyd:</p>
<div class="highlight"><pre><span></span>curl http://&lt;IP-DO-VPS&gt;:6800/schedule.json -d project=&lt;nome-do-projeto&gt; -d spider=&lt;nome-do-spider&gt;
</pre></div>


<p>Eu utilizei o <a href="http://curl.haxx.se/">curl</a>, mas você poderia utilizar qualquer ferramenta que possa fazer um GET ou POST dependendo do que deseja fazer, todas as opções da API do Scrapyd, você pode ver em:</p>
<p>http://scrapyd.readthedocs.org/en/latest/api.html</p>
<p>Finalmente podemos ver se o nosso crawler está rodando corretamente acessando a interface web do scrapyd que visualiza os <strong>jobs</strong>:</p>
<p>http://&#60;IP-DO-VPS&#62;:6800/jobs</p>
<h3>Considerações finais</h3>
<p>Eu gosto bastante da simplicidade do Scrapyd, entretanto ele não oferece muitas possibilidades para uma melhor visualização dos itens coletados e a interface web se restringe a visualizar, não é possível adicionar spiders e projetos. Além disso, ele deixa "público" o acesso aos jobs e itens - uma forma de burlar isso seria fazendo um proxy com o nginx ou apache e colocando uma autenticação como o <a href="https://en.wikipedia.org/wiki/Basic_access_authentication">basic http authentication</a>.</p>
<p>Esta série acaba por aqui mas em breve irei falar mais sobre esses dados coletados mas o foco não será mais o scrapy, será a análise desses dados.</p>
    <div class="hline"></div>
    <div class="spacing"></div>
    <p>
        <a class="btn btn-theme" href="/tags/python" role="button" title="Tag 'python'">python</a>
        <a class="btn btn-theme" href="/tags/dados" role="button" title="Tag 'dados'">dados</a>
    </p>
    <div class="spacing"></div>
    <h6>COMPARTILHAR:</h6>
    <p class="share">
		<a target="_blank" href="https://twitter.com/home?status=Usando%20o%20Scrapy%20e%20o%20Rethinkdb%20para%20capturar%20e%20armazenar%20dados%20imobili%C3%A1rios%20-%20Parte%20III%20http%3A//www.gilenofilho.com.br/usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-iii"><i class="fa fa-twitter"></i></a>
		<a href="https://www.facebook.com/sharer/sharer.php?u=http%3A//www.gilenofilho.com.br/usando-o-scrapy-e-o-rethinkdb-para-capturar-e-armazenar-dados-imobiliarios-parte-iii"><i class="fa fa-facebook"></i></a>
	</p>
</article>

    <section class="row" id="comments">
        <div class="col-md-12">
            <h4>Comentários</h4>
            <div id="disqus_thread"></div>
            <script type="text/javascript">
                /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
                    var disqus_shortname = 'gilenofilho'; // required: replace example with your forum shortname
                var disqus_identifier = 'gilenofilho.com.br' + window.location.pathname;
                /* * * DON'T EDIT BELOW THIS LINE * * */
                (function () {
                    var dsq = document.createElement('script');
                    dsq.type = 'text/javascript';
                    dsq.async = true;
                    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                })();
            </script>
            <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
        </div>
    </section>
                </div>
                <div class="col-md-4">
                    <h4><a href="https://www.udemy.com/construa-um-e-commerce-com-python-3-e-django/?couponCode=websitegilenofilho">Construa um E-Commerce com Python e Django</a></h4>
                    <a href="https://www.udemy.com/construa-um-e-commerce-com-python-3-e-django/?couponCode=websitegilenofilho">
                        <img src="/images/django-udemy.jpg" alt="Construa um E-Commerce com Python e Django" class="img-responsive" />
                    </a>
    		 		<h4>Pesquisar</h4>
    		 		<div class="hline"></div>
		 			<p>
		 				<br>
                        <form class="" action="https://www.google.com/search" method="get">
                            <input name="q" type="text" class="form-control" placeholder="Pesquisar..." />
                            <input type="hidden" name="sitesearch" value="http://www.gilenofilho.com.br">
                        </form>
		 			</p>
    		 		<div class="spacing"></div>

    		 		<h4>Categorias</h4>
    		 		<div class="hline"></div>
                        <p><a href="/categorias/cursos"><i class="fa fa-angle-right"></i> cursos</a> <span class="badge badge-theme pull-right">6</span></p>
                        <p><a href="/categorias/palestras"><i class="fa fa-angle-right"></i> palestras</a> <span class="badge badge-theme pull-right">5</span></p>
                        <p><a href="/categorias/tutoriais"><i class="fa fa-angle-right"></i> tutoriais</a> <span class="badge badge-theme pull-right">12</span></p>
                        <p><a href="/categorias/utils"><i class="fa fa-angle-right"></i> utils</a> <span class="badge badge-theme pull-right">4</span></p>

    		 		<div class="spacing"></div>

    		 		<h4>Artigos Recentes</h4>
    		 		<div class="hline"></div>
					<ul class="popular-posts">
		                <li>
		                    <p><a href="/python-datasets">Bibliotecas Python para carregar Dataset's</a></p>
		                    <em>Publicado em Seg 02 janeiro 2017</em>
		                </li>
		                <li>
		                    <p><a href="/como-funciona-o-orm-do-django">Como funciona o ORM do Django</a></p>
		                    <em>Publicado em Sex 15 julho 2016</em>
		                </li>
		                <li>
		                    <p><a href="/curso-gratuito-de-django-com-python-3">Curso Gratuito de Django com Python 3</a></p>
		                    <em>Publicado em Qua 23 março 2016</em>
		                </li>
		                <li>
		                    <p><a href="/programacao-felicidade-mercado-e-outras-coisas">Programação, felicidade, mercado e outras coisas...</a></p>
		                    <em>Publicado em Ter 10 novembro 2015</em>
		                </li>
		            </ul>

    		 		<div class="spacing"></div>

    		 		<h4>Tags</h4>
    		 		<div class="hline"></div>
		 			<p>
		            	<a class="btn btn-theme" href="/tags/python" role="button">python</a>
		            	<a class="btn btn-theme" href="/tags/dados" role="button">dados</a>
		            	<a class="btn btn-theme" href="/tags/django" role="button">django</a>
		            	<a class="btn btn-theme" href="/tags/database" role="button">database</a>
		            	<a class="btn btn-theme" href="/tags/video-aula" role="button">video-aula</a>
		            	<a class="btn btn-theme" href="/tags/lifestyle" role="button">lifestyle</a>
		            	<a class="btn btn-theme" href="/tags/comunidade" role="button">comunidade</a>
		            	<a class="btn btn-theme" href="/tags/startup" role="button">startup</a>
		            	<a class="btn btn-theme" href="/tags/design" role="button">design</a>
		            	<a class="btn btn-theme" href="/tags/inteligencia-artificial" role="button">inteligência-artificial</a>
		            	<a class="btn btn-theme" href="/tags/universidade" role="button">universidade</a>
		            	<a class="btn btn-theme" href="/tags/pythonbrasil" role="button">pythonbrasil</a>
		            	<a class="btn btn-theme" href="/tags/engenharia-de-avaliacoes" role="button">engenharia-de-avaliações</a>
		            	<a class="btn btn-theme" href="/tags/deploy" role="button">deploy</a>
		            	<a class="btn btn-theme" href="/tags/evento" role="button">evento</a>
		 			</p>
                </div>
            </div>

            <!-- Footer -->
<div id="footerwrap">
   <div class="container">
       <div class="row">
           <div class="col-md-6">
               <h4>Sobre</h4>
               <div class="hline-w"></div>
               <p>
    Website e Blog de Gileno Filho, escrevo sobre: Desenvolvimento,
    Python, Django, Ciência de Dados, Engenharia de Avaliações,
    Inteligência Artificial e Design Minimalista.
</p>
           </div>
           <div class="col-md-6">
               <h4>Social</h4>
               <div class="hline-w"></div>
               <p>
                   <a class="white-text" href="https://github.com/gileno" title="GitHub">
                       <i class="fa fa-github"></i>
                   </a>
                   <a class="white-text" href="https://twitter.com/gilenofilho" title="Twitter">
                       <i class="fa fa-twitter"></i>
                   </a>
                   <a class="white-text" href="https://www.facebook.com/gilenofilho" title="Facebook">
                       <i class="fa fa-facebook"></i>
                   </a>
                   <a class="white-text" href="mailto:contato@gilenofilho.com.br" title="E-mail">
                       <i class="fa fa-envelope"></i>
                   </a>
               </p>
           </div>
       </div>
   </div>
</div>
            <!-- Scripts -->
            <script   src="https://code.jquery.com/jquery-2.2.4.min.js"   integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>
            <script src="/theme/js/bootstrap.min.js"></script>
        </main>
    </body>
</html>